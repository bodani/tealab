scope: {{ PG_CLUSTER_NAME }}
namespace: /pg/
name: {{ application_name }}

restapi:
  listen: {{ inventory_hostname }}:8008
  connect_address: {{ inventory_hostname }}:8008
#  cafile: /etc/ssl/certs/ssl-cacert-snakeoil.pem
#  certfile: /etc/ssl/certs/ssl-cert-snakeoil.pem
#  keyfile: /etc/ssl/private/ssl-cert-snakeoil.key
  authentication:
    username: {{ REST_API_USERNAME }}
    password: {{ REST_API_PASSWORD }}

ctl:
  insecure: true # Allow connections to Patroni REST API without verifying certificates
#  certfile: /etc/ssl/certs/ssl-cert-snakeoil.pem
#  keyfile: /etc/ssl/private/ssl-cert-snakeoil.key
#  cacert: /etc/ssl/certs/ssl-cacert-snakeoil.pem

#--------------------------------------------------------------#
# log
#--------------------------------------------------------------#
log:
  level: INFO                           #  NOTEST|DEBUG|INFO|WARNING|ERROR|CRITICAL
  dir: /var/log/patroni                 #  patroni log dir
  file_size: 33554432                   #  32MB log triggers log rotation
  file_num: 20                          #  keep at most 30x32MB = 1GB log
  dateformat: '%Y-%m-%d %H:%M:%S %z'    #  IMPORTANT: discard milli timestamp
  format: '%(asctime)s %(levelname)s: %(message)s'


etcd3:
  #Provide host to do the initial discovery of the cluster topology:
  hosts: '{{ ETCD_HOSTS }}'
#  username: 
#  password: 
  protocol: https
  cacert: /etc/ssl/certs/patroni/ca.pem
  cert: /etc/ssl/certs/patroni/client-crt.pem
  key: /etc/ssl/certs/patroni/client-key.pem

bootstrap:
  # this section will be written into Etcd:/<namespace>/<scope>/config after initializing new cluster
  # and all other cluster members will use it as a `global configuration`
  dcs:
    ttl: 30
    loop_wait: 10
    retry_timeout: 10
    maximum_lag_on_failover: 1048576
    primary_start_timeout: 300
    synchronous_mode: false
    failsafe_mode: true
    #standby_cluster:
      #host: 127.0.0.1
      #port: 1111
      #primary_slot_name: patroni
    postgresql:
      use_pg_rewind: true
#      use_slots: true
      #------------------------------------------------------------#
      # how to react to database operations
      #------------------------------------------------------------#
      # event callback script log: /var/log/patroni/callback.log
      callbacks:
        on_start: /etc/patroni/callbacks/pg-failover-callback
        on_stop: /etc/patroni/callbacks/pg-failover-callback
        on_reload: /etc/patroni/callbacks//pg-failover-callback
        on_restart: /etc/patroni/callbacks//pg-failover-callback
        on_role_change: /etc/patroni/callbacks//pg-failover-callback
      #------------------------------------------------------------#
      # how to create replica
      #------------------------------------------------------------#
      # create replica method: default pg_basebackup
      create_replica_methods:
        - basebackup
        - pgbackrest
      basebackup:
        - max-rate: '100M'
        - checkpoint: fast
        - verbose
        - progress
      pgbackrest:
        command: /usr/bin/pgbackrest --stanza=pg-meta --delta restore
        keep_data: true
        no_params: true
        no_leader: true
        no_leader: true

      parameters:
        wal_level: hot_standby
        hot_standby: "on"
        max_connections: 100
        max_worker_processes: 8
        wal_keep_segments: 8
        max_wal_senders: 10
        max_replication_slots: 10
        max_prepared_transactions: 0
        max_locks_per_transaction: 64
        wal_log_hints: "on"
        track_commit_timestamp: "off"
        archive_mode: "on"
        archive_timeout: 1800s
        archive_command: /bin/true
#        archive_command: mkdir -p ../wal_archive && test ! -f ../wal_archive/%f && cp %p ../wal_archive/%f
#      recovery_conf:
#        restore_command: cp ../wal_archive/%f %p
        password_encryption: scram-sha-256
#        ssl: on                                 # enable server ssl
#        ssl_cert_file: '{{PG_DATA}}/cert/server.crt'    # public cert path
#        ssl_key_file: '{{PG_DATA}}/cert/server.key'     # private key path
#        ssl_ca_file: '{{PG_DATA}}/pki/ca.crt'          # ca file path

        log_destination: csvlog                 # use standard csv log
        logging_collector: on                   # enable csvlog
        log_directory: {{PG_DATA}}/log/postgres         # postgres log dir
        # log_filename: 'postgresql-%a.log'     # weekly auto-recycle
        log_filename: 'postgresql-%Y-%m-%d.log' # YYYY-MM-DD full log retention
        log_checkpoints: on                     # log checkpoint info
        log_lock_waits: on                      # log lock wait info
        log_replication_commands: on            # log replication info
        log_statement: ddl                      # log ddl change
        log_min_duration_statement: 1000         # log slow query (>1s)
        #------------------------------------------------------#
        # STATISTICS
        #------------------------------------------------------#
        track_io_timing: on                     # collect io statistics
        track_functions: all                    # track all functions (none|pl|all)
        track_activity_query_size: 8192         # max query length in pg_stat_activity

        #------------------------------------------------------#
        # AUTOVACUUM
        #------------------------------------------------------#
        log_autovacuum_min_duration: 1s         # log autovacuum activity take more than 1s
        autovacuum_max_workers: 3               # default autovacuum worker 3
        autovacuum_naptime: 1min                # default autovacuum naptime 1min
        autovacuum_vacuum_scale_factor: 0.08    # fraction of table size before vacuum   20% -> 8%
        autovacuum_analyze_scale_factor: 0.04   # fraction of table size before analyze  10% -> 4%
        autovacuum_vacuum_cost_delay: -1        # default vacuum cost delay: same as vacuum_cost_delay
        autovacuum_vacuum_cost_limit: -1        # default vacuum cost limit: same as vacuum_cost_limit
        autovacuum_freeze_max_age: 1000000000   # age > 1 billion triggers force vacuu

        #------------------------------------------------------#
        # CLIENT
        #------------------------------------------------------#
        deadlock_timeout: 500ms                      # 500ms for deadlock
        idle_in_transaction_session_timeout: 10min  # 10min timeout for idle in transaction
        #------------------------------------------------------#
        # CUSTOMIZED OPTIONS
        #------------------------------------------------------#
        # extensions
        shared_preload_libraries: 'pg_repack, pg_stat_statements, auto_explain'
        # auto_explain
        auto_explain.log_min_duration: 5s       # auto explain query slower than 5s
        auto_explain.log_analyze: true          # explain analyze
        auto_explain.log_verbose: true          # explain verbose
        auto_explain.log_timing: true           # explain timing
        auto_explain.log_nested_statements: true

        # pg_stat_statements
        pg_stat_statements.max: 10000           # 5000 -> 10000 queries
        pg_stat_statements.track: all           # track all statements (all|top|none)
        pg_stat_statements.track_utility: off   # do not track query other than CRUD
        pg_stat_statements.track_planning: off  # do not track planning metrics


  # some desired options for 'initdb'
  initdb:  # Note: It needs to be a list (some options need values, others are switches)
  - encoding: UTF8
  - data-checksums
  - locale: C
  - lc-collate: C
  - lc-ctype: en_US.UTF8

  pg_hba:  # Add following lines to pg_hba.conf after running 'initdb'
  # For kerberos gss based connectivity (discard @.*$)
  #- host replication replicator 127.0.0.1/32 gss include_realm=0
  #- host all all 0.0.0.0/0 gss include_realm=0
  - host replication replicator 127.0.0.1/32 scram-sha-256
  - host all all 0.0.0.0/0 scram-sha-256
  - hostssl all all 0.0.0.0/0 scram-sha-256

  # Additional script to be launched after initial cluster creation (will be passed the connection URL as parameter)
# post_init: /usr/local/bin/setup_cluster.sh

  # Some additional users users which needs to be created after initializing new cluster
  users:
    {{MON_USER}}:
      options:
        - pg_monitor

    replicator:
      password: 'DBUser.Replicator'

postgresql:
#------------------------------------------------------------#
# how to connect to postgres
#------------------------------------------------------------#
  bin_dir: /usr/pgsql-10/bin/
  data_dir: {{PG_DATA}}
  config_dir: {{PG_DATA}}
  pgpass: /var/lib/pgsql/.pgpass
  listen: 127.0.0.1,{{inventory_hostname}}:5432
  connect_address: {{inventory_hostname}}:5432
  use_unix_socket: true # default: /var/run/postgresql, /tmp

#------------------------------------------------------------#
# who to connect to postgres
#------------------------------------------------------------#
  authentication:
    superuser:
      username: postgres
    replication:
      username: replicator
      password: 'rep-pass'
    rewind:  # Has no effect on postgres 10 and lower
      username: rewind_user
      password: 'rewind_password'

  # Server side kerberos spn
#  krbsrvname: postgres
#  parameters:
    # Fully qualified kerberos ticket file for the running user
    # same as KRB5CCNAME used by the GSS
#   krb_server_keyfile: /var/spool/keytabs/postgres
#    unix_socket_directories: '..'  # parent directory of data_dir
  # Additional fencing script executed after acquiring the leader lock but before promoting the replica
  #pre_promote: /path/to/pre_promote.sh

#watchdog:
#  mode: automatic # Allowed values: off, automatic, required
#  device: /dev/watchdog
#  safety_margin: 5

tags:
    nofailover: false
    noloadbalance: false
    clonefrom: false
    nosync: false
    version:  '14'